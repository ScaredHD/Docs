\documentclass[UTF8]{ctexart}
\hfuzz=4pt
\usepackage{anyfontsize}
\usepackage{geometry}
    \geometry{left=4cm,right=4cm,top=2cm,bottom=2cm}
\usepackage{parskip}
    \setlength{\parindent}{0em}
    \setlength{\parskip}{1em}
\usepackage{amsmath, amssymb, amsthm, mathtools}
    \renewcommand*{\proofname}{proof}
\usepackage{thmtools}
    \renewcommand\qedsymbol{$\blacksquare$}
    \declaretheorem[numberwithin=section,shaded={rulecolor=cyan,rulewidth=2pt,bgcolor=white}]{definition}
    \declaretheorem[numberwithin=section,shaded={rulecolor=orange,rulewidth=2pt, bgcolor=white}]{theorem} 
    \newtheoremstyle{mystyle}{1em plus .2 em minus .2em}{1em plus .2 em minus .2em}{}{}{\bfseries}{.}{.5em}{}
    \theoremstyle{mystyle}
    \newtheorem{axiom}{Axiom}[section]
    \newtheorem{lemma}{Lemma}[section]
    \newtheorem{proposition}{Proposition}[section]
    \newtheoremstyle{myremark}{1em plus .2 em minus .2em}{1em plus .2 em minus .2em}{}{}{\itshape}{.}{.5em}{}
    \theoremstyle{myremark}
    \newtheorem*{remark}{Remark}
    \theoremstyle{plain}
    \newtheorem{corollary}{Corollary}[section]
\usepackage{xcolor} 	 % 颜色
\usepackage{graphicx} 	 % 引用图片
\usepackage{float}
\usepackage{centernot}
\usepackage{esvect} 	 % 向量箭头 \vv{} 
\usepackage{esint} 	 % 积分符号
\usepackage{mathrsfs}
\usepackage{csquotes}


% font
\newcommand{\ve}[1]{\boldsymbol{\mathbf{#1}}}
\newcommand{\unit}[1]{\boldsymbol{\mathbf{\hat{#1}}}}
\newcommand{\mr}{\mathrm}
\newcommand{\mcal}{\mathcal}
\newcommand{\mscr}{\mathscr}
\newcommand{\E}{\mathrm e}
\renewcommand{\I}{\mathrm i}
\newcommand{\R}{\mathbb R}
\newcommand{\Z}{\mathbb Z}
\newcommand{\N}{\mathbb N}
\newcommand{\Q}{\mathbb Q}
\newcommand{\C}{\mathbb C}
\newcommand{\transp}{^{\top}}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\GL}{GL}
\DeclareMathOperator{\im}{im}
\DeclarePairedDelimiter\set{\{}{\}}


\pagestyle{empty}

\begin{document}
\section{Group}
\subsection{Law of Composition}
\begin{definition}[\text{Composition}]
    Composition (or Law of composition) on a set S is to combine two element $ a, b \in S $, to get another element $ p $ in $ S $: \[ S \times S \to S \,.\] Here, $ \times $ means Cartesian product of two sets. We can denote the composition in several ways: \[ p = a b \quad p = a \cdot b \quad p = a \circ b \quad p = a + b \,.\]
\end{definition}

We will often use $ ab $ (or $ a \cdot b $ when neccessary) to denote the composition of $ a $ and $ b $ in this document.

\paragraph{Example}
\begin{itemize}
    \item In the set $ \N $, operation ``add'' $ + $ is a law of composition. It takes two elements of $ a, b \in \N $ and gives an element $ a + b \in \N $. e.g.\ $ (2, 3) \mapsto 5 $, $ (5, 1) \mapsto 6 $
    \item In the set $ \R $, operation ``multiply'' $ \cdot $ is a law of composition. It takes two elements of $ a, b \in \R $ and gives an element $ a \cdot b \in \R $. e.g.\ $ (-1, 4) \mapsto -4 $, $ (2, 3.5) \mapsto 7 $
\end{itemize}

Note that the definition of composition natrually brings out the property of closure --- the composition of two element of $ S $ is still in the same set.

A way of defining composition is using functions. $ f \colon S \times S \to S $, so for $ a, b \in S $, $ f(a, b) $ is the composition of $ a $ and $ b $.

\begin{definition}[\text{Associativity}]
    For element $ a $, $ b $ and $ c $, if the composition satisfies $ (ab)c = a(bc) $, then the composition is \textbf{associative}.
\end{definition}

For multiple element $ a_1 $, $ a_2 $, $ \dots $, $ a_n $, there's only one distinct way to define the composition of them:
\[ a_1 a_2 \cdots a_n = (a_1 \cdots a_i) (a_i \cdots a_n) \,,\]

where $ 1 \leqslant i < n $. For instance,
\[ a_1 a_2 a_3 a_4 = a_1 (a_2 a_3 a_4) = (a_1 a_2) (a_3 a_4) = (a_1 a_2 a_3) a_4 = a_1 (a_2 a_3) a_4 \,.\]

\begin{definition}[\text{Commutativity}]
    The composition of two element $ a $ and $ b $ is called \textbf{commutative} if $ ab = ba $.
\end{definition}

\paragraph{Example}
Addtion in $ \R $ is commutative: $ a, b \in \R $, $ a + b = b + a $.

\subsection{Special elements}
\begin{definition}[\text{Identity element}]
    If $ \forall s \in S $, $ \exists e \in S $ such that $ es = s $, then $ e $ is the \textbf{left identity} of $ S $. Likewise, $ e $ is the \textbf{right identity} if $ se = s $. If $ e $ is both left identity and right identity, then it's called a \textbf{two-sided identity} or simply \textbf{identity}.
\end{definition}

If we use multiplication to represent composition, then $ 1 $ is commonly used as the symbol of identity. And $ 0 $ is often identity for addition representation.

\paragraph{Example}
\begin{itemize}
    \item Concider zero in $ \Z $. For all $ a \in \Z $, $ 0 + a = a $, so $ 0 $ is the left identity. And by commutativity we also have $ a + 0 = a $, so $ 0 $ is also the right identity. Therefore, $ 0 $ is the identity of addition on $ \Z $
    \item $ 1 $ is the identity of multiplication on $ \R $, because $ \forall a \in Z $, $ 1 \cdot a = a \cdot 1 = a $
\end{itemize}

\begin{definition}[\text{Inverse}]
    Let $ 1 $ be the identity. If $ \forall a \in S $, $ \exists l \in S $ such that $ l a = 1 $, then $ l $ is called the \textbf{left inverse} of $ a $. Likewise, $ a r = 1 $ then $ r $ is called the \textbf{right inverse} of $ a $. If $ b $ is both left and right inverse of $ a $, then it's called the \textbf{two-sided inverse} or simply \textbf{inverse} of $ a $, denoted by $ a^{-1} $.
\end{definition}

\paragraph{Example}
\begin{itemize}
    \item $ -3 $ is the additive inverse of $ 3 $ in $ \R $, because $ (-3) + 3 = 3 + (-3) = 0 $ and $ 0 $ is the identity of addition.
    \item $ 1/2 $ is the multiplicative inverse of $ 2 $ in $ \R $, because $ (1/2) \times 2 = 2 \times (1/2) = 1 $ and $ 1 $ is the identity of multiplication.
\end{itemize}

A fraction $ \dfrac{a}{b} $ is exactly the composition of $ a $ and $ b^{-1} $. And the notation $ \dfrac{a}{b} $ is not recommended, because sometimes the composition is not commutative, therefore $ a b^{-1} $ and $ b^{-1} a $ are different.

The notations like $ a^n $ or $ a^{-n} $, $ n \in \N $ can be recursively defined as below:
\[ a^{n + 1} \coloneqq a^n a  \,,\]
\[ a^{-n - 1} = a^{-n} a^{-1} \,,\] 
\[ a^0 = 1 \,.\]

\begin{proposition}
    If inverse of $ a $ exists, which means $ a $ has left inverse and right inverse, then the left and right inverse are equal, therefore the inverse is unique.
\end{proposition}

\begin{proof}
    If $ a \in G $ has left inverse $ b $ and right inverse $ c $. Concider element $ bac \in G $, $ (ba)c = 1 c = c $, and $ b(ac) = b 1 = b $. By associativity, $ (ba)c = b(ac) $, so $ c = b $. The inverse is unique.
\end{proof}

\begin{proposition}
    $ (a b)^{-1} = b^{-1} a^{-1} $.
\end{proposition}

\begin{proof}
    $ (ab)^{-1} (ab) = 1 $ is true, multiply $ b^{-1} $ on the right for both sides. $ (a b)^{-1} (a b) b^{-1} = 1 \cdot b^{-1} $, which is $ (a b)^{-1} a (b b^{-1}) = (a b)^{-1} a \cdot 1 = b^{-1} $. This time multiply $ a^{-1} $ on the right for both sides: $ (a b)^{-1} a a^{-1} = b^{-1} a^{-1} $, the left-hand side is exactly $ (a b)^{-1} $.
\end{proof}

And this can be easily generalized to $ n $ elements (using associativity and induction):
\[ (a_1 a_2 \dots a_n)^{-1} = a_n^{-1} \dots a_2^{-1} a_1^{-1} \,.\]

\subsection{Group}
\begin{definition}
    A group $ (G, \cdot) $ is a set $ G $ equipped with a binary operation $ \cdot $ which follows four axioms, namely \textbf{closure}, \textbf{associativity}, \textbf{identity} and \textbf{invertibility}.
\end{definition}    

\begin{remark}
    If a group is commutative, then it's called \textbf{abelian group}.
\end{remark}

The four axioms are explained below:
\paragraph{closure}
For all $ a, b $ in $ G $, the result of operation $ \cdot $ is still in $ G $. This can be written in the form: $ \forall a, b \in G, a \cdot b \in G $.

\paragraph{associativity}
$ \forall a, b, c \in G $, $ (a \cdot b) \cdot c = a \cdot (b \cdot c) $.

\paragraph{identity}
$ \exists\ e \in G $ such that, $ \forall a \in G $, the equation $ e \cdot a = a \cdot e = a $ holds. Such an element is unique and is called the \textbf{identity element}.

\paragraph{invertibility}
For each $ a \in G $, $ \exists\ b $ in $ G $, commonly denoted $ a^{-1} $, such that $ a \cdot b = b \cdot a = e $, where $ e $ is the identity element.

We use ordered pair to denote $ (G, \cdot) $ a set $ G $ equipped with operation $ \cdot $. So the two parts --- set and its operation --- together forms the algebraic structure. This is critical, because strictly speaking, a set on its own can not be a group. But informally, it's common to say that a set $ G $ is a group, if no ambiguity is caused.

\paragraph{Example}
These are some familiar abelian groups: $ (\Z, +) $, $ (\R, +) $, $ (\R^+, \times) $, $ (\C, +) $, $ (\C, \times) $. Take $ (\R^+, +) $ for example. 

\begin{enumerate}
    \item Two the addition of positive real numbers $ a, b $ is still a real number (closure)
    \item $ (a + b) + c = a + (b + c) $, which is associativity
    \item For any given $ a \in \R^+ $, $ 1 \times a = a \times 1 = a $ holds, which indicates that $ 1 $ is the multiplicative identity of $ \R^+ $
    \item For any given $ a \in \R^+ $, $ \exists a^{-1} $ such that $ a^{-1} \times a = a \times a^{-1} = 1 $ holds, which indicates all $ a \in \R^+ $ is invertable
\end{enumerate}

Therefore, $ (\R^+, \times) $ is a group. Also, for any positive real number $ a $ and $ b $, $ a \times b = b \times a $. So $ (\R^+, \times) $ is also an abelian group.


\begin{remark}
    Note that $ (\R, \times) $ is not a group, because $ 0 $ is not invertable: $ \centernot\exists r \in \R $ such that $ r \times 0 = 0 \times r = 1 $.
\end{remark}


\begin{proposition}
    Left identity $ e_L $ and right identity $ e_R $ of a group are the same.
\end{proposition}

\begin{proof}
    $ e_L = e_L e_R = e_R $.
\end{proof}


\begin{proposition}
    The (two-sided) identity of $ G $, if exists, must be unique.
\end{proposition}

\begin{proof}
    Let $ e, e' \in G $ identities and $ e \neq e' $, i.e.\ $ \forall a \in G $, $ e = e i $ as well as $ e' a = a $. Hence $ e' = e' e = e $.
\end{proof}

The two propositions above can be concluded with quote below (from Wikipedia):
\begin{displayquote}
    ... it is possible for $ (S, *) $ to have several left identities. In fact, every element can be a left identity. In a similar manner, there can be several right identities. But if there is both a right identity and a left identity, then they must be equal, resulting in a single two-sided identity. 
\end{displayquote}

Since groups are sets equipped with operations, and we have cardinality to describe how many elements we have in a set, it's natural to have a similar concept to describe the number of elements contained in a group.

\begin{definition}[\text{Order of a group}]
    The order of a group describe the number of elements contained in this group. Suppose we have group $ (G, \cdot) $, the order of this group equals the cardinality of $ G $, denoted by $ |G| $.
\end{definition}

\paragraph{Example}
The previous example, abelian group $ (\Z, +) $ is an infinite group, because $ \Z $ is an infinite set.

Because of invertibility property, a group follows \textbf{cancellation law}.

\begin{proposition}{\text{Cancellation law}}
    Let $ a $, $ b $, $ c $ be elements of a group $ G $: 
    \begin{itemize}
        \item if $ ac = bc $ or $ ca = cb $ then $ a = b $
        \item if $ ac = c $ or $ ca = c $ then $ a = 1 $
    \end{itemize}
\end{proposition}

\begin{proof}
    Proofs of all cases are analogous --- by multiplying $ c^{-1} $ to both sides.
\end{proof}

Following corollary is the contrapositive of last proposition which is supported by invertability.

\begin{corollary}
    Let $ a $, $ b $, $ c $ be elements of a group $ G $: 
    \begin{itemize}
        \item if $ a \neq b $, then $ ca \neq cb $ and $ ac \neq bc $
        \item if $ a \neq 1 $, then $ ca \neq c $ and $ ac \neq c $
    \end{itemize}
\end{corollary}

Concider matrices. Not all matrices are invertable, so we can't just say matrix with multiplication operation is or is not a group.

\begin{definition}[\text{General linear group}]
    The general linear group of degree $ n $ is the set of $ n \times n $ invertable matrices:
    \[ \GL_n \coloneqq \set{n \times n \text{ invertable matrices}} \,.\]

    And enable to distinguish what kind of elements we are having in the matrices, notations like $ \GL_n(\R) $ or $ \GL_n(\C) $ are used.
\end{definition}

\subsection{半群}
半群是弱于群的概念.
\begin{definition}[\text{半群}]
    $ (G, \cdot) $ 被称为半群, 当且仅当 $ G $ 对 $ \cdot $ 封闭且 $ \cdot $ 满足结合律.
\end{definition}

如果 $ (G, \cdot) $ 中存在 $ a $, 满足 $ a a = a $. 则称 $ a $ 为 $ \cdot $ 运算的幂等元. 借助下面的引理可以证明, 有限的半群中必然存在幂等元.

\begin{lemma}
    如果对于有限半群 $ G $ 的元素 $ a $, 存在正整数 $ k \geqslant 2 $, 满足 $ a^k = a $, 则 $ G $ 中存在幂等元.
\end{lemma}

\begin{proof}
    对于 $ a^k = a $, 若 $ k = 2 $, $ a $ 为幂等元, 引理得证. 若 $ k > 2 $, 则将等式两边同时乘以 $ a^{k - 2} $. 得到 $ a^{2(k - 1)} = a^{k - 1} $. 即 $ \left( a^{k - 1} \right)^2 = a^{k - 1} $, 而 $ a^{k - 1} \in G $, 所以 $ G $ 中存在幂等元 $ a^{k - 1} $.
\end{proof}

\begin{proposition}
    有限的半群必然包含幂等元, 即若 $ G $ 为有限的半群, 则存在 $ a \in G $, 使得 $ aa = a $.
\end{proposition}

\begin{proof}
    对于任意 $ a \in G $, 考虑无限序列 \[ \left( a^{2^p} \right)_{p = 0}^\infty \colon \quad a, a^2, a^4, a^8, a^{16}, \dots \]

    由于封闭性, 序列中每一项都在 $ G $ 中, 于是必然存在不同的 $ s $, $ t $ 满足 $ a^{\displaystyle 2^s} = a^{\displaystyle 2^t} $. 因为如果不然, 序列中的每一项互不相同, 则 $ G $ 不可能有限. 不失一般性地假设 $ s > t $, 于是有: \[ a^{\displaystyle 2^{s}} = a^{\displaystyle 2^{t + (s - t)}} = a^{\displaystyle 2^{t} 2^{\displaystyle s - t}} = a^{\displaystyle 2^t} \,,\]

    于是得到 $ \left( a^{\displaystyle 2^t} \right)^{\displaystyle 2^{s - t}} = a^{\displaystyle 2^t} $. 于是我们找到了 $ b = a^{\displaystyle 2^t} \in G $, 使得存在 $ k = 2^{s - t} $, 满足 $ b^k = b $, 根据上一个引理, $ G $ 中存在幂等元.
\end{proof}


\subsection{子群}
\begin{definition}[\text{子群}]
    $ (G, \cdot) $ 为一个群, $ H \subseteq G $, 若 $ H $ :
    \begin{itemize}
        \item 满足封闭性
        \item 存在单位元
        \item 每个元素都可逆
    \end{itemize}
    则称 $ H $ 为 $ G $ 的子群, 记作 $ H \le G $.

    每个群 $ G $ 都有两个明显的子群, 称为平凡子群, 即单位元构成的集合 $ \set{1} $ 以及 $ G $ 本身. 若 $ H \le G $, 且 $ H $ 不是平凡子群, 则称 $ H $ 为 $ G $ 的真子群, 记作 $ H < G $.
\end{definition}

子群只需满足三个条件, 因为结合律自动转移到子集上: $ \forall a, b, c \in H $, $ a, b, c \in G $, $ G $ 具有结合律, 所以 $ H $ 也满足结合律. 换句话说, 群 $ G $ 的子集 $ H $ 也是一个群, 则 $ H $ 为 $ G $ 的子群.


定义 $ \Z a $ 为 $ a $ 的整倍数构成的集合:
\[ \Z a \coloneqq \set{k a \mid k \in \Z} \,.\]

等价的定义为:
\[ \Z a \coloneqq \set{n \mid \exists k \in \Z, n = k a} \,.\]

\paragraph{例}
\[ \Z 0 = \set{0} \,,\]
\[ \Z 1 = \set{0, 1, -1, 2, -2, \dots} = \Z \,,\]
\[ \Z 2 = \set{0, 2, -2, 4, -4, \dots} \,,\]
\[ \Z 5 = \set{0, 5, -5, 10, -10, \dots} \,.\]


可以证明, $ \Z a $ 为 $ (\Z, +) $ 的子群. $ \Z a $ 满足封闭性: $ \forall n_1, n_2 \in \Z a $, $ \exists k_1, k_2 \in \Z $ 满足 $ n_1 = k_1 a $, $ n_2 = k_2 a $. 故 $ n_1 + n_2 = (k_1 + k_2) a $, 而 $ k_1 + k_2 \in Z $, 所以 $ n_1 + n_2 \in \Z a $.

此外, $ 0 $ 为 $ \Z a $ 的单位元; 对于任意 $ a \in \Z a $, 都能找到 $ -a \in \Z a $, 使得 $ a + (-a) = 0 $, 即 $ \Z a $ 中每个元素可逆.

 
由于 $ G $ 和其子群 $ H $ 共享唯一的单位元, 如果 $ G $ 的单位元 $ 1 $ 也在 $ H $ 中, 那么 $ 1 $ 也一定是 $ H $ 的单位元.

$ \Z a $ 的重要之处在于下面的命题:
\begin{proposition}
    $ (\Z, +) $ 的子群一定有 $ \Z a $ 的形式.
\end{proposition}


下一个重要的抽象子群例子为:
\begin{definition}[\text{循环群}]
    群 $ G $ 中的元素 $ x $ 生成的子群: 
    \[ \langle x \rangle \coloneqq \set{1, x, x^{-1}, x^2, x^{-2}, \dots} \]
    称为 $ G $ 循环子群. 如果一个群 $ H $ 中任意元素都能写成某一元素 $ x $ 的幂次 $ x^n $, 即能由单个元素 $ x $ 生成, 则该群被称为循环群.
\end{definition}

\paragraph{例}
考虑 $ (\R, \times) $ 的元素 $ -1 $. $ -1 $ 的不同幂次得到的元素可能是相同的:
\[ \begin{array}{c}
    \vdots \\
    (-1)^2 = 1 \\
    (-1)^3 = -1 \\
    (-1)^4 = 1 \\
    \vdots
\end{array} \]

所以实数乘群中, $ -1 $ 的生成的循环子群为 $ \langle -1 \rangle = \set{1, -1} $.


\begin{proposition}
    $ S = \set{n \in \Z \mid x^n = 1} $ 为 $ (\Z, +) $ 的子群.
\end{proposition}

\begin{proof}
    封闭性: $ \forall n_1, n_2 \in S $, $ x^{n_1} = 1 $, $ x^{n_2} = 1 $, $ x^{n_1} x^{n_2} = x^{n_1 + n_2} = 1 $, 所以 $ n_1 + n_2 \in S $.

    单位元: 只需考虑 $ (\Z, +) $ 的单位元 $ 0 $ 是否在 $ S $ 中即可. 显然, $ x^0 = 1 $, $ 0 \in S $, 所以 $ S $ 存在单位元 $ 0 $.

    逆元: $ \forall n \in S $, $ x^n = 1 $, 所以 $ x^{-n} = x^{-n} x^n = x^0 = 1 $. 所以 $ -n \in S $.
\end{proof}


\subsection{同态}
\begin{definition}[\text{同态 (Homomophism)}]
    同态 $ \varphi \colon G \to G' $ 是 群 $ G $ 到 $ G' $ 的映射, 该映射满足:
    \[ \forall a, b \in G, \qquad \varphi(a b) = \varphi(a) \varphi(b) \,.\]

    和映射一样, 同态也有像的概念:
    \[ \varphi(G) \coloneqq \im \varphi \coloneqq \set{\varphi(x) \mid x \in G} \,.\]
\end{definition}

\begin{remark}
    注意此处 $ G $ 和 $ G' $ 中的运算都是用乘法表示的, 不代表它们必须是同一种运算. 严格地定义同态应该是下面这样的, $ \varphi \colon (G, \circ) \to (G', *) $, 其中:
    \[ \forall a, b \in G, \qquad \varphi(a \circ b) = \varphi(a) * \varphi(b) \,.\]
\end{remark}

换句话说, 先在 $ G $ 中对 $ a, b $ 做运算, 然后在映射到 $ G' $ 中; 和先映射 $ a, b $ 到 $ G' $ 中, 然后做 $ G' $ 中的运算; 两种路径得到的结果是一样的. 即: $ G $ 和 $ G' $ 中对应的两组元素, 分别在各自的群内合成, 得到的结果也是满足相同的对应关系. 如: $ a' = \varphi(a) $, $ b' = \varphi(b) $. 则 $ a \circ b = a' * b' $.

\paragraph{例}
$ \exp \colon (\R, +) \to (\R, \times) $, $ \exp(x) = \mr e^x $, 为一个同态, 因为 $ \exp(x + y) = \exp (x) \exp (y) $. 反过来, 指数函数不是 $ (\R, \times) $ 到 $ (\R, +) $ 的同态. 对于 $ x, y \in \R $, 先合成 $ x y $, 再映射 $ \exp (x y) $; 和先映射 $ \exp(x), \exp(y) $, 再合成 $ \exp(x) + \exp(y) $ 是不同的.

绝对值 $ |~| \colon (\R, \times) \to (\R, \times) $ 也是一个同态, $ |x y| = |x| |y| $.

\paragraph{几个明显的同态}
平凡同态: $ \varphi \colon G \to G' $, 将 $ G $ 中的每个元素映射到 $ G' $ 中的单位元. 于是 $ \forall a, b \in G $, $ \varphi(a) = \varphi(b) = \varphi(a b) = e $. $ \varphi(a b) = e = ee = \varphi(a) \varphi(b) $.

对于 $ H \le G $, 存在包含同态: $ i \colon H \to G $, $ i(x) = x $. $ H $ 和 $ G $ 的合成法则一致, $ \forall x \in H $, $ x \in G $, $ i(x) = x $. 所以 $ i (x y) = x y = i(x) i(y) $.

\begin{proposition}
    令 $ \varphi \colon G \to G' $ 为同态. 
    \begin{enumerate}
        \item $ a_1, a_2, \dots, a_k \in G $, $ \varphi(a_1 a_2 \cdots a_k) = \varphi(a_1) \varphi(a_2) \cdots \varphi(a_k) $
        \item 恒等元映射到恒等元: $ \varphi(1_G) = 1_{G'} $
        \item 逆元映射为逆元: $ \varphi(a^{-1}) = \varphi^{-1}(a) $
    \end{enumerate}
\end{proposition}

\begin{proof}
    (1) 通过归纳法.

    (2) $ \varphi(a) = \varphi(1_G a) = \varphi(1_G) \varphi(a) $. 两边同时右乘 $ \varphi(a) $ 在 $ G' $ 中的逆元: $ \varphi(a) \varphi^{-1}(a) = \varphi(1_G) \varphi(a) \varphi^{-1}(a) $. 而 $ \varphi(a) \varphi^{-1}(a) $ 为 $ G' $ 的单位元 $ 1_{G'} $. 所以 $ 1_{G'} = \varphi(1_G) 1_{G'} = \varphi(1_G) $.

    (3) $ a a^{-1} = 1_G $, 同时应用 $ \varphi $, $ \varphi(a a^{-1}) = \varphi(a) \varphi(a^{-1}) = \varphi(1_G) = 1_{G'} $. 两边同时乘以 $ \varphi^{-1}(a) $, $ \varphi^{-1}(a) \varphi(a) \varphi(a^{-1}) = \varphi(a^{-1}) = \varphi^{-1}(a) 1_{G'} = \varphi^{-1} (a) $.
\end{proof}

\begin{proposition}
    同态的像为陪域的子群. $ \varphi \colon H \to G $, 则 $ \varphi(H) $ 为 $ G $ 的子群.
\end{proposition}

\begin{proof}
    封闭性: 对于任意 $ x, y \in \varphi(H) $, $ \exists a, b \in H $, $ x = \varphi(a) $, $ y = \varphi(b) $. $ x y = \varphi(a) \varphi(b) = \varphi(a b) $, 由于 $ ab \in H $, $ \varphi(a b) \in \varphi(H) $. 所以 $ x y \in \varphi(H) $.

    单位元: $ \forall x \in \varphi(H) $, $ \exists a \in H $, $ \varphi(a) = x $. $ \varphi(a) = \varphi(a e_H) = \varphi(a) \varphi(e_H) $. 即 $ x = x \varphi(e_H) $. 同样地, 从 $ \varphi(a) = \varphi(e_H a) $ 可以得到 $ x = \varphi(e_H) x $. 所以 $ \varphi(e_H) $ 为 $ \varphi(H) $ 的单位元.

    逆元: $ \forall x \in \varphi(H) $, $ \exists a \in H $, $ \varphi(a) = x $. $ \varphi(a a^{-1}) = \varphi(a) = \varphi(a^{-1}) = x \varphi(a^{-1}) = \varphi(e_H) = e_G $. 同理可以得到, $ \varphi(a^{-1}) x = e_G $. 所以 $ \varphi(a^{-1}) $ 为 $ x $ 的逆元.
\end{proof}


同态的核是定义域中所有映射到陪域单位元的元素集合.
\begin{definition}[\text{核(kernel)}]
    设 $ \varphi \colon G \to G' $ 为同态. 定义同态 $ \varphi $ 的核为: \[ \ker \varphi \coloneqq \set{x \in G \mid \varphi(x) = 1_{G'}} \,.\]
\end{definition}


容易验证下面的命题.
\begin{proposition}
    同态的核是定义域的子群. 设 $ \varphi \colon G \to G' $, $ \ker \varphi \le G $.
\end{proposition}

注意到, $ \ker \varphi $ 为 $ G $ 的子集, $ G $ 的单位元 $ e_G $ 也在 $ \ker \varphi $ 中, 故 $ e_G $ 是 $ \ker \varphi $ 的单位元.



\end{document}